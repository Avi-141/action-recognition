## 准备

开始神经网络的搭建前参考了一些质量较高的开源项目，但是这些开源项目有以下问题：

1. 只针对特定的数据集（比如 UCF-101 和 HMDB-51）进行训练
2. 实现方式较为复杂或者实现方式不是 LSTM
3. 对硬件设备的要求过高

最后在参考了一些基础的 LSTM 后，进行了神经网络的实现。训练框架采用 PyTorch，参考了以下 repo 的代码：

[https://github.com/chaoyuaw/pytorch-coviar.git](https://github.com/chaoyuaw/pytorch-coviar.git)

## 编写

开始编写前对需求作一定的分析。项目需要实现的基本功能有：

1. 训练参数的自定义和保存
2. 神经网络的训练和验证
3. 神经网络的继续训练
4. 评估神经网络性能

一些可以增加的功能有：

1. 支持视频直接训练和测试
2. 采集摄像头拍摄数据并进行实时的识别

### 神经网络

神经网络的基本结构如之前所示，具体的神经网络实现在 `model.py` 中。

神经网络的输入为图片序列，同一个视频提取的单帧图片使用矩阵索引进行访问。

神经网络的结构具体可以分为四层：

1. CNN 特征提取层，使用预训练的 CNN 对图片进行特征的读取
2. 全连接层，用于连接 CNN 和 LSTM，并减小特征的数量
3. LSTM 层，用于建立各帧图片之间的联系
4. 全连接层，作为输出层将分类结果进行输出

### 训练参数

开始一个神经网络的训练必须定义：

1. 优化器
2. 目标函数

PyTorch 框架提供了常用的优化器，定义优化器时需要指定优化器的必要参数，特别是学习率。因为学习率会明显影响训练的速度和最后的正确率，所以有必要对学习率进行动态地调整。Adam 这类优化器虽然有自动降低学习率的功能，但是为了尽可能提高争取率，依旧还是有一定的必要进行学习率的动态调整。

使用梯度下降进行训练必须定义目标函数，最常见的 RNN 对输入都有一个输出，但是单一视频是有一个标签，没法直接对应每个视频的每一帧图片的输出。

<div align="center">
  <img src="/imgs/rnn1.png">
</div>

关于时间展开的循环神经网络，在序列结束时具有单个输出。使用该网络虽然可以直接得到误差，但是没有考虑序列中间输出，会降低一定的准确率。

<div align="center">
  <img src="/imgs/rnn2.png">
</div>

考虑到每个视频的帧图像的意义不同：前几帧的图像虽然也能识别出部分行为，但是没有动作变化的特征，所以输出结果参考意义不大；最后几帧的图像有较多的序列信息，其的预测输出更接近于整个序列的预测输出。所以最后的目标函数将每帧图像的输出按照权重进行调整，并计算了调整后的输出作为目标函数的输入。

### 不定长序列的训练

因为数据集中视频的长度不相等，相应的导出的图片序列长度不同。小批量训练可以使梯度下降方向更加正确，但是小批量训练 RNN 要求输入序列长度一致，所以必须进行一定的处理。

## 训练

### 训练代码验证

正式进行训练前，需要编写正确的训练代码。

该阶段从原数据集中抽取了五个分类，每个分类选择两个较小的训练数据，所以数据集的大小为 10。

代码参考的部分结构简单的 LSTMs 和实际需要使用的网络差别较大，需要进行大幅修改，并且修改后的代码必须保证：

1. 训练、验证、预测以及模型的保存和加载都可以正常进行，各阶段不会出现报错
2. 随着训练的进行，在训练集上的 loss 要有明显降低，也就是训练要收敛

该阶段最重要的任务就是将实现的代码进行简单验证，并逐步完善应有的功能，防止正式训练时出现较大改动导致的项目重构。

### 正式训练

这个阶段出现了一些第一阶段没有出现的问题：

1. 训练集中存在一些较大的数据，在网络训练时会使显存溢出
2. 训练的速度太慢，没法短期内对训练的效果进行评估

为了解决这些问题，对网络进行了优化并删除了中间量，使用了一些训练框架的新特性，但是收效甚微，最后采取临时升级硬件的方法：

1. 在云主机平台上进行训练
2. 购置新的 GPU 进行训练

购置新 GPU 之前，使用 P40 的 GPU 云主机进行了一段时间的训练，训练可以正常完成，证明神经网络的设计基本可行。

### 网络的修改

通过使用更好的 GPU 来进行训练明显加快了训练速度，并且在 AlexNet 上也并没有出现显存不足的问题。考虑到 ResNet 的特征提取效果更好，所以尝试基于 ResNet 搭建 LSTM。使用 ResNet-18 搭建 LSTM 虽然修改不大，但是因为 ResNet-18 参数更多，又再次出现了显存不足的问题。

至此阶段，为了减少显存占用已经做了一定的努力，但是如果对于 ResNet 中最小的 ResNet-18 依旧存在显存不足的问题，那么很可能需要修改一下算法。

通过查询资料后得知，框架提供的预训练网络已经有较好的特征提取效果，即使进行微调训练也不能得到足够的收益。即使进行微调训练一般也不会将整个 CNN+LSTM 的网络进行训练，一般只训练 CNN 部分。实际训练时将正向传播分成 CNN 和 LSTM 两部分，CNN 得到的特征图作为 LSTM 的输入，并训练 LSTM。经过这样的处理，LSTM 在训练时并不会将梯度传递到 CNN 部分，也不需要记录 CNN 的历史数据。实际编写时可以用 PyTorch 的参数冻结，使得反向传播不经过 CNN，并且不记录 CNN 的数据历史，明显降低显存占用，也加快了训练的速度。

### 网络的优化和继续训练

虽然神经网络的训练已经可以正常进行了，但是实际训练的效果却较差，所以必须进行不断的调参来优化网络。

代码编写时已经考虑到了继续训练，每次训练都会将预测效果最好的模型的参数进行保存，所以继续训练时将需要的参数进行加载即可。

实际在该过程的训练中，发现模型收敛困难，所以多次回溯第一步使用小数据集进行 Debug 并进行训练参数的调整。

因为上一阶段的调整，使得训练对 GPU 的负担减轻，空闲出更多的计算资源来增加网络的深度。

## 其他发现

提供的数据集其实就是 HMDB-51，但是删除了其中一个分类，应该是为了防止直接使用训练好的模型。
