## 神经网络实现

开始神经网络的搭建前参考了一些质量较高的开源项目，但是这些开源项目有以下问题：

1. 只针对特定的数据集（比如 UCF-101 和 HMDB-51）进行训练
2. 实现方式较为复杂或者实现方式不是 LSTM
3. 对硬件设备的要求过高

最后在参考了一些基础的 LSTM 后，进行了神经网络的实现。训练框架采用 PyTorch，参考了一些 repo 的代码：

[https://github.com/siqinli/GestureRecognition-PyTorch.git](https://github.com/siqinli/GestureRecognition-PyTorch.git)

[https://github.com/chaoyuaw/pytorch-coviar.git](https://github.com/chaoyuaw/pytorch-coviar.git)

在神经网络的搭建基础上实现了以下功能：

1. 神经网络训练参数的自定义和保存
2. 神经网络的训练和验证
3. 神经网络的继续训练
4. 评估神经网络性能

## 训练过程

### 训练代码验证

正式进行训练前，需要编写正确的训练代码。

该阶段从原数据集中抽取了五个分类，每个分类选择两个较小的训练数据，所以数据集的大小为 10。

代码参考的部分结构简单的 LSTMs 和实际需要使用的网络差别较大，需要进行大幅修改，并且修改后的代码必须保证：

1. 训练、验证、预测以及模型的保存和加载都可以正常进行，各阶段不会出现报错
2. 随着训练的进行，在训练集上的 loss 要有明显降低，也就是训练要收敛

该阶段最重要的任务就是将实现的代码进行简单验证，并逐步完善应有的功能，防止正式训练时出现较大改动导致的项目重构。

### 正式训练

这个阶段出现了一些第一阶段没有出现的问题：

1. 训练集中存在一些较大的数据，在网络训练时会使显存溢出
2. 训练的速度太慢，没法短期内对训练的效果进行评估

为了解决这些问题，对网络进行了优化并删除了中间量，使用了一些训练框架的新特性，但是收效甚微，最后采取临时升级硬件的方法：

1. 在云主机平台上进行训练
2. 购置新的 GPU 进行训练

购置新 GPU 之前，使用 P40 的 GPU 云主机进行了一段时间的训练，训练可以正常完成，证明神经网络的设计基本可行。

### 网络的优化和继续训练

虽然神经网络的训练已经可以正常进行了，但是实际训练的效果却较差，所以必须进行不断的调参来优化网络。

代码编写时已经考虑到了继续训练，每次训练都会将预测效果最好的模型的参数进行保存，所以继续训练时将需要的参数进行加载即可。
